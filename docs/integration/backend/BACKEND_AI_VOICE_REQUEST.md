# Backend API Request: AI ìŒì„± ìƒë‹´ WebSocket ì—”ë“œí¬ì¸íŠ¸

**ì‘ì„±ì¼**: 2025-01-10
**ìš”ì²­ íŒ€**: Frontend Team
**ìš°ì„ ìˆœìœ„**: High (í•µì‹¬ ê¸°ëŠ¥)

---

## ğŸ“‹ ìš”ì•½

ì‚¬ìš©ìê°€ ìŒì„±ìœ¼ë¡œ ë§í•˜ë©´ ìë™ìœ¼ë¡œ AI ì‘ë‹µì„ ìƒì„±í•˜ê³  ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì‹¤ì‹œê°„ ìŒì„± ìƒë‹´ ê¸°ëŠ¥ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. ë°±ì—”ë“œì—ì„œ WebSocketì„ í†µí•´ AI ì‘ë‹µ ìš”ì²­ì„ ë°›ê³  ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ¯ ëª©ì 

í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©ìì˜ ìŒì„±ì´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ë˜ë©´:
1. ìë™ìœ¼ë¡œ ì±„íŒ…ì°½ì— ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
2. ë°±ì—”ë“œì— AI ì‘ë‹µ ìš”ì²­ ì „ì†¡ (í˜„ì¬ ê°ì • ìƒíƒœ í¬í•¨)
3. ë°±ì—”ë“œëŠ” AIì—ê²Œ ìš”ì²­ í›„ ì‘ë‹µì„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ì†¡
4. í”„ë¡ íŠ¸ì—”ë“œëŠ” ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì±„íŒ…ì°½ì— í‘œì‹œí•˜ê³  TTSë¡œ ì¬ìƒ

---

## ğŸ”Œ WebSocket ìŠ¤í™

### ì±„ë„
```
wss://bemorebackend.onrender.com/ws/session/{session_id}
```

### í”„ë¡ íŠ¸ì—”ë“œ â†’ ë°±ì—”ë“œ (ìš”ì²­)

**Message Type**: `request_ai_response`

```typescript
{
  type: 'request_ai_response',
  data: {
    message: string,          // ì‚¬ìš©ì ë©”ì‹œì§€ (STT ê²°ê³¼)
    emotion: string | null,   // í˜„ì¬ ê°ì • ('happy', 'sad', 'angry', 'anxious', 'neutral', etc.)
    timestamp: number         // ìš”ì²­ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
  }
}
```

### Request Example
```json
{
  "type": "request_ai_response",
  "data": {
    "message": "ìš”ì¦˜ íšŒì‚¬ì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ì•„ìš”",
    "emotion": "anxious",
    "timestamp": 1704902400000
  }
}
```

---

## ğŸ“¤ ë°±ì—”ë“œ â†’ í”„ë¡ íŠ¸ì—”ë“œ (ì‘ë‹µ)

AI ì‘ë‹µì€ **3ë‹¨ê³„ ìŠ¤íŠ¸ë¦¬ë°**ìœ¼ë¡œ ì „ì†¡ë©ë‹ˆë‹¤:

### 1. ì‘ë‹µ ì‹œì‘ (Stream Begin)
```typescript
{
  type: 'ai_stream_begin',
  data: {}
}
```

### 2. ì‘ë‹µ ì²­í¬ (Stream Chunk) - ì—¬ëŸ¬ ë²ˆ ì „ì†¡
```typescript
{
  type: 'ai_stream_chunk',
  data: {
    chunk: string  // AI ì‘ë‹µ ì¡°ê° (ì˜ˆ: "ìŠ¤íŠ¸ë ˆìŠ¤", "ë¥¼ ë°›ê³ ", " ê³„ì‹œëŠ”êµ°ìš”...")
  }
}
```

### 3. ì‘ë‹µ ì™„ë£Œ (Stream Complete)
```typescript
{
  type: 'ai_stream_complete',
  data: {}
}
```

### 4. ì‘ë‹µ ì‹¤íŒ¨ (Stream Error)
```typescript
{
  type: 'ai_stream_error',
  data: {
    error: string  // ì˜¤ë¥˜ ë©”ì‹œì§€
  }
}
```

---

## ğŸ”§ ë°±ì—”ë“œ êµ¬í˜„ ê°€ì´ë“œ

### FastAPI ì˜ˆì‹œ

```python
from fastapi import WebSocket
from typing import AsyncGenerator
import asyncio

# AI í´ë¼ì´ì–¸íŠ¸ (Gemini, OpenAI ë“±)
async def generate_ai_response(user_message: str, emotion: str | None, session_id: str) -> AsyncGenerator[str, None]:
    """
    AI ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„±

    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        emotion: í˜„ì¬ ê°ì • ìƒíƒœ
        session_id: ì„¸ì…˜ ID (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒìš©)

    Yields:
        AI ì‘ë‹µ ì²­í¬ (í•œ ê¸€ì ë˜ëŠ” í•œ ë‹¨ì–´ì”©)
    """
    # 1. ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ì´ì „ ëŒ€í™” ë§¥ë½)
    conversation_history = await get_conversation_history(session_id)

    # 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê°ì • ê¸°ë°˜)
    system_prompt = build_system_prompt(emotion)

    # 3. AIì—ê²Œ ìš”ì²­ (ìŠ¤íŠ¸ë¦¬ë°)
    # Gemini ì˜ˆì‹œ:
    model = genai.GenerativeModel('gemini-1.5-pro')

    # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ…
    messages = []
    for msg in conversation_history:
        messages.append({
            "role": msg["role"],  # "user" or "model"
            "parts": [msg["content"]]
        })

    # í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    messages.append({
        "role": "user",
        "parts": [user_message]
    })

    # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
    response = model.generate_content(
        messages,
        stream=True,
        generation_config={
            "temperature": 0.7,
            "top_p": 0.8,
            "max_output_tokens": 1024,
        }
    )

    # ì²­í¬ ë‹¨ìœ„ë¡œ yield
    for chunk in response:
        if chunk.text:
            yield chunk.text
            await asyncio.sleep(0.05)  # ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„ ì¡°ì ˆ


def build_system_prompt(emotion: str | None) -> str:
    """ê°ì •ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    base_prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ê³µê°ì ì´ê³  ë”°ëœ»í•œ íƒœë„ë¡œ ë‚´ë‹´ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³ ,
ì¸ì§€í–‰ë™ì¹˜ë£Œ(CBT) ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ë„ì›€ì„ ì œê³µí•˜ì„¸ìš”."""

    emotion_guidance = {
        "anxious": "ë‚´ë‹´ìê°€ ë¶ˆì•ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ˆì •ê°ì„ ì£¼ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”.",
        "sad": "ë‚´ë‹´ìê°€ ìš°ìš¸í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê³µê°ê³¼ ìœ„ë¡œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”.",
        "angry": "ë‚´ë‹´ìê°€ í™”ê°€ ë‚˜ ìˆìŠµë‹ˆë‹¤. ê°ì •ì„ ìˆ˜ìš©í•˜ê³  ì§„ì •ì‹œí‚¤ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”.",
        "happy": "ë‚´ë‹´ìì˜ ê¸ì •ì ì¸ ìƒíƒœë¥¼ ê°•í™”í•˜ì„¸ìš”.",
        "neutral": "ì¤‘ë¦½ì ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”."
    }

    if emotion and emotion in emotion_guidance:
        return f"{base_prompt}\n\ní˜„ì¬ ê°ì • ìƒíƒœ: {emotion_guidance[emotion]}"

    return base_prompt


@app.websocket("/ws/session/{session_id}")
async def websocket_session_endpoint(websocket: WebSocket, session_id: str):
    """ì„¸ì…˜ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket.accept()

    try:
        while True:
            # ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive_json()

            # AI ì‘ë‹µ ìš”ì²­ ì²˜ë¦¬
            if message.get("type") == "request_ai_response":
                data = message.get("data", {})
                user_message = data.get("message", "")
                emotion = data.get("emotion")
                timestamp = data.get("timestamp")

                # ë¡œê¹…
                logger.info(f"[AI Request] session={session_id}, emotion={emotion}, message={user_message[:50]}...")

                try:
                    # 1. ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì•Œë¦¼
                    await websocket.send_json({
                        "type": "ai_stream_begin",
                        "data": {}
                    })

                    # 2. AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
                    full_response = ""
                    async for chunk in generate_ai_response(user_message, emotion, session_id):
                        await websocket.send_json({
                            "type": "ai_stream_chunk",
                            "data": {"text": chunk}
                        })
                        full_response += chunk

                    # 3. ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì•Œë¦¼
                    await websocket.send_json({
                        "type": "ai_stream_complete",
                        "data": {}
                    })

                    # 4. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
                    await save_conversation(
                        session_id=session_id,
                        user_message=user_message,
                        ai_response=full_response,
                        emotion=emotion,
                        timestamp=timestamp
                    )

                except Exception as e:
                    logger.error(f"[AI Error] {e}")
                    await websocket.send_json({
                        "type": "ai_stream_error",
                        "data": {"error": str(e)}
                    })

    except WebSocketDisconnect:
        logger.info(f"[WebSocket] Session {session_id} disconnected")
```

---

## ğŸ’¾ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥

ëŒ€í™”ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ì—¬ ë§¥ë½ì„ ìœ ì§€í•©ë‹ˆë‹¤:

### MongoDB ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ
```javascript
{
  sessionId: "sess_abc123",
  conversations: [
    {
      timestamp: 1704902400000,
      message: "ìš”ì¦˜ íšŒì‚¬ì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ì•„ìš”",
      aiResponse: "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ê³  ê³„ì‹œëŠ”êµ°ìš”. ì–´ë–¤ ìƒí™©ì—ì„œ íŠ¹íˆ í˜ë“œì‹ ê°€ìš”?",
      emotion: "anxious",
      createdAt: ISODate("2025-01-10T12:00:00Z")
    },
    // ...
  ]
}
```

### PostgreSQL ìŠ¤í‚¤ë§ˆ ì˜ˆì‹œ
```sql
CREATE TABLE conversations (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(255) NOT NULL,
    user_message TEXT NOT NULL,
    ai_response TEXT NOT NULL,
    emotion VARCHAR(50),
    timestamp BIGINT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    FOREIGN KEY (session_id) REFERENCES sessions(session_id)
);

CREATE INDEX idx_conversations_session ON conversations(session_id);
CREATE INDEX idx_conversations_timestamp ON conversations(timestamp);
```

---

## ğŸ¨ AI í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œë¼ì¸

### ê¸°ë³¸ ì›ì¹™
1. **ê³µê°ì  ê²½ì²­**: ë‚´ë‹´ìì˜ ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ê³  ìˆ˜ìš©
2. **êµ¬ì²´ì  ì§ˆë¬¸**: ëª¨í˜¸í•œ ìƒí™©ì„ êµ¬ì²´í™”í•˜ëŠ” ì§ˆë¬¸
3. **CBT ê¸°ë²•**: ì¸ì§€ ì™œê³¡ íƒì§€ ì‹œ ì¬êµ¬ì„± ìœ ë„
4. **ì§§ê³  ëª…í™•**: í•œ ë²ˆì— í•œ ê°€ì§€ ì£¼ì œì— ì§‘ì¤‘ (2-3ë¬¸ì¥)

### ê°ì •ë³„ ì‘ë‹µ ì˜ˆì‹œ

**ë¶ˆì•ˆ(anxious)**:
- "ë§ì´ ë¶ˆì•ˆí•˜ì…¨ê² ì–´ìš”. ì–´ë–¤ ìƒê°ì´ ë“œì…¨ë‚˜ìš”?"
- "ê·¸ëŸ° ìƒí™©ì—ì„œ ë¶ˆì•ˆí•œ ê±´ ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì´ì—ìš”."

**ìŠ¬í””(sad)**:
- "í˜ë“  ì‹œê°„ì„ ë³´ë‚´ê³  ê³„ì‹œëŠ”êµ°ìš”. ì–´ë–¤ ì¼ì´ ìˆì—ˆë‚˜ìš”?"
- "ìŠ¬í”ˆ ê°ì •ì„ ëŠë¼ëŠ” ê²ƒë„ ê´œì°®ì•„ìš”."

**ë¶„ë…¸(angry)**:
- "í™”ê°€ ë‚˜ì…¨êµ°ìš”. ê·¸ëŸ° ê°ì •ì„ ëŠë¼ëŠ” ê²Œ ë‹¹ì—°í•´ìš”."
- "ë¬´ì—‡ì´ ê°€ì¥ í™”ë‚˜ê²Œ í–ˆë‚˜ìš”?"

**ì¤‘ë¦½/í‰ì˜¨(neutral/happy)**:
- "ì˜¤ëŠ˜ì€ ì–´ë–¤ í•˜ë£¨ë¥¼ ë³´ë‚´ì…¨ë‚˜ìš”?"
- "ê·¸ ê²½í—˜ì— ëŒ€í•´ ë” ìì„¸íˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"

---

## ğŸ” í”„ë¡ íŠ¸ì—”ë“œ ì½”ë“œ ìœ„ì¹˜

AI ì‘ë‹µ ìš”ì²­ì„ ì „ì†¡í•˜ëŠ” ì½”ë“œ:

**íŒŒì¼**: `src/App.tsx` (line 169-181)

```typescript
// ğŸ¤– Auto-trigger AI response after user speech
sendToSession({
  type: 'request_ai_response',
  data: {
    message: text,
    emotion: currentEmotion,
    timestamp: Date.now()
  }
});
```

AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°ì„ ìˆ˜ì‹ í•˜ëŠ” ì½”ë“œ:

**íŒŒì¼**: `src/App.tsx` (line 273-286)

```typescript
// AI streaming events (example schema)
if (message.type === 'ai_stream_begin') {
  window.dispatchEvent(new CustomEvent('ai:begin'));
}
if (message.type === 'ai_stream_chunk') {
  const d = message.data as { chunk?: string };
  window.dispatchEvent(new CustomEvent('ai:append', { detail: { chunk: d?.chunk ?? '' } }));
}
if (message.type === 'ai_stream_complete') {
  window.dispatchEvent(new CustomEvent('ai:complete'));
}
if (message.type === 'ai_stream_error') {
  const d = message.data as { error?: string };
  window.dispatchEvent(new CustomEvent('ai:fail', { detail: { error: d?.error ?? 'AI stream failed' } }));
}
```

---

## âœ… í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. WebSocket ì—°ê²° í…ŒìŠ¤íŠ¸
```python
import asyncio
import websockets
import json

async def test_ai_response():
    uri = "ws://localhost:8000/ws/session/test_session_123"
    async with websockets.connect(uri) as websocket:
        # AI ì‘ë‹µ ìš”ì²­
        await websocket.send(json.dumps({
            "type": "request_ai_response",
            "data": {
                "message": "ì•ˆë…•í•˜ì„¸ìš”",
                "emotion": "neutral",
                "timestamp": 1704902400000
            }
        }))

        # ì‘ë‹µ ìˆ˜ì‹ 
        while True:
            response = await websocket.recv()
            message = json.loads(response)
            print(f"Received: {message}")

            if message["type"] == "ai_stream_complete":
                break

asyncio.run(test_ai_response())
```

### 2. í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸
1. í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰: `npm run dev`
2. ì„¸ì…˜ ì‹œì‘
3. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
4. ìŒì„±ìœ¼ë¡œ ë§í•˜ê¸°: "ì•ˆë…•í•˜ì„¸ìš”"
5. í™•ì¸ ì‚¬í•­:
   - ì±„íŒ…ì°½ì— ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
   - AI ì‘ë‹µì´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°
   - TTSë¡œ AI ì‘ë‹µ ìŒì„± ì¬ìƒ

---

## â±ï¸ êµ¬í˜„ ìš°ì„ ìˆœìœ„

**ìš°ì„ ìˆœìœ„**: ğŸ”´ High (í•µì‹¬ ê¸°ëŠ¥)

### í•„ìˆ˜ êµ¬í˜„ ì‚¬í•­
- [ ] WebSocket `/ws/session/{session_id}` ì—”ë“œí¬ì¸íŠ¸ì— `request_ai_response` í•¸ë“¤ëŸ¬ ì¶”ê°€
- [ ] AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„ (Gemini/OpenAI/Claude)
- [ ] ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ (ì„¸ì…˜ë³„)
- [ ] ê°ì • ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ (`ai_stream_error`)

### ê¶Œì¥ êµ¬í˜„ ì‚¬í•­
- [ ] ëŒ€í™” ë§¥ë½ ìœ ì§€ (ìµœê·¼ 5-10ê°œ ë©”ì‹œì§€)
- [ ] AI ì‘ë‹µ ì†ë„ ìµœì í™” (ì²­í¬ í¬ê¸° ì¡°ì ˆ)
- [ ] ì‘ë‹µ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§ (ì‘ë‹µ ì‹œê°„, í† í° ìˆ˜)
- [ ] ë¶€ì ì ˆí•œ ë‚´ìš© í•„í„°ë§

---

## ğŸ“Š ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

- **ì‘ë‹µ ì‹œì‘ ì‹œê°„**: ì²« ë²ˆì§¸ ì²­í¬ < 2ì´ˆ
- **ìŠ¤íŠ¸ë¦¬ë° ì†ë„**: ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° ì†ë„ (50-100ms/ì²­í¬)
- **ì „ì²´ ì‘ë‹µ ì‹œê°„**: < 10ì´ˆ (ì¼ë°˜ì ì¸ ë‹µë³€)
- **ë™ì‹œ ì—°ê²°**: ì„¸ì…˜ë‹¹ 1ê°œ WebSocket ì—°ê²° ìœ ì§€

---

## ğŸ” ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

1. **ì„¸ì…˜ ê²€ì¦**: WebSocket ì—°ê²° ì‹œ ìœ íš¨í•œ session_id í™•ì¸
2. **Rate Limiting**: ì‚¬ìš©ìë‹¹ ë¶„ë‹¹ ìš”ì²­ ì œí•œ (ì˜ˆ: 10íšŒ)
3. **ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ**: user_message ìµœëŒ€ 2000ì
4. **ë¯¼ê° ì •ë³´ ë¡œê¹… ë°©ì§€**: ëŒ€í™” ë‚´ìš© ë¡œê·¸ ì‹œ ê°œì¸ì •ë³´ ë§ˆìŠ¤í‚¹
5. **AI ì•ˆì „ì„±**: ë¶€ì ì ˆí•œ ë‚´ìš© ìƒì„± ë°©ì§€ (content filter)

---

## ğŸ“ ë¬¸ì˜

êµ¬í˜„ ì¤‘ ì§ˆë¬¸ì´ ìˆìœ¼ë©´ í”„ë¡ íŠ¸ì—”ë“œ íŒ€ì— ì—°ë½ì£¼ì„¸ìš”!

**ê´€ë ¨ íŒŒì¼**:
- Frontend: `src/App.tsx`, `src/components/AIChat/AIChat.tsx`
- Types: `src/types/index.ts`

**ì°¸ê³  ë¬¸ì„œ**:
- [Gemini API - Streaming](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#generate-a-text-stream)
- [OpenAI API - Streaming](https://platform.openai.com/docs/api-reference/streaming)
- [FastAPI WebSocket](https://fastapi.tiangolo.com/advanced/websockets/)
