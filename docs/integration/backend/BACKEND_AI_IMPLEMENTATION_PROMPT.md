# ğŸ¤– BeMore AI ìŒì„± ìƒë‹´ ë°±ì—”ë“œ êµ¬í˜„ - Claude ì‹¤í–‰ í”„ë¡¬í”„íŠ¸

**ì‘ì„±ì¼**: 2025-01-14
**ëŒ€ìƒ**: ë°±ì—”ë“œ ê°œë°œì (FastAPI + Python)
**ëª©ì **: Claude Codeì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸°í•˜ì—¬ AI ìŒì„± ìƒë‹´ ê¸°ëŠ¥ ì¦‰ì‹œ êµ¬í˜„

---

## ğŸ“‹ ë³µì‚¬í•˜ì—¬ Claude Codeì— ë¶™ì—¬ë„£ê¸°

```
ë‹¹ì‹ ì€ FastAPI ë°±ì—”ë“œ ê°œë°œìì…ë‹ˆë‹¤. BeMore AI ì‹¬ë¦¬ ìƒë‹´ ì‹œìŠ¤í…œì˜ ì‹¤ì‹œê°„ AI ìŒì„± ìƒë‹´ ê¸°ëŠ¥ì„ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸

BeMoreëŠ” ì‹¤ì‹œê°„ ì–¼êµ´ ê°ì • ì¸ì‹ + AI ìŒì„± ìƒë‹´ì„ ì œê³µí•˜ëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì…ë‹ˆë‹¤.
- **í”„ë¡ íŠ¸ì—”ë“œ**: React + TypeScript (ì´ë¯¸ ì™„ë£Œ)
- **ë°±ì—”ë“œ**: FastAPI + Python (AI ì‘ë‹µ ê¸°ëŠ¥ë§Œ í•„ìš”)
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL (Supabase)
- **AI**: Gemini 1.5 Pro (Google)

**í˜„ì¬ ìƒí™©**:
âœ… í”„ë¡ íŠ¸ì—”ë“œëŠ” ì™„ì „íˆ êµ¬í˜„ë¨
âœ… WebSocket ì—°ê²° ì„¤ì •ë¨
âœ… ì‚¬ìš©ì ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ
âŒ AI ì‘ë‹µ ìƒì„± ê¸°ëŠ¥ë§Œ ì—†ìŒ (ì´ ì‘ì—…ì´ í•„ìš”)

**í”„ë¡ íŠ¸ì—”ë“œ ë™ì‘ ë°©ì‹**:
1. ì‚¬ìš©ìê°€ ìŒì„±ìœ¼ë¡œ ë§í•¨ â†’ STT â†’ í…ìŠ¤íŠ¸
2. í”„ë¡ íŠ¸ì—”ë“œê°€ WebSocketìœ¼ë¡œ `request_ai_response` ë©”ì‹œì§€ ì „ì†¡
3. **ë°±ì—”ë“œê°€ AI ì‘ë‹µ ìƒì„±** (â† ì´ ë¶€ë¶„ì„ êµ¬í˜„í•´ì•¼ í•¨)
4. AI ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ í”„ë¡ íŠ¸ì—”ë“œì— ì „ì†¡
5. í”„ë¡ íŠ¸ì—”ë“œê°€ TTSë¡œ ìŒì„± ì¬ìƒ

---

## ğŸ¯ êµ¬í˜„ ëª©í‘œ

ë‹¤ìŒ ê¸°ëŠ¥ë“¤ì„ êµ¬í˜„í•´ì£¼ì„¸ìš”:

### 1. WebSocket ë©”ì‹œì§€ í•¸ë“¤ëŸ¬ ì¶”ê°€
- ì—”ë“œí¬ì¸íŠ¸: `/ws/session/{session_id}`
- ìƒˆ ë©”ì‹œì§€ íƒ€ì…: `request_ai_response` ì²˜ë¦¬
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ: `ai_stream_begin` â†’ `ai_stream_chunk` (ì—¬ëŸ¬ ë²ˆ) â†’ `ai_stream_complete`

### 2. Gemini AI í†µí•©
- Google Gemini 1.5 Pro API ì‚¬ìš©
- ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ êµ¬í˜„
- ê°ì • ê¸°ë°˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (8ê°œ ê°ì • ì§€ì›)

### 3. ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬
- PostgreSQL `conversations` í…Œì´ë¸” ìƒì„±
- ì‚¬ìš©ì ë©”ì‹œì§€ + AI ì‘ë‹µ ì €ì¥
- ì„¸ì…˜ë³„ ìµœê·¼ 10ê°œ ëŒ€í™” ì¡°íšŒ (ë§¥ë½ ìœ ì§€)

### 4. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë³´ì•ˆ
- Rate limiting (ì‚¬ìš©ìë‹¹ ë¶„ë‹¹ 10íšŒ)
- ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (2000ì)
- ì„¸ì…˜ ID ê²€ì¦
- ì—ëŸ¬ ì‹œ `ai_stream_error` ì „ì†¡

---

## ğŸ“¡ WebSocket ë©”ì‹œì§€ ìŠ¤í™

### í”„ë¡ íŠ¸ì—”ë“œ â†’ ë°±ì—”ë“œ (ìš”ì²­)

```json
{
  "type": "request_ai_response",
  "data": {
    "message": "ìš”ì¦˜ íšŒì‚¬ì—ì„œ ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë§ì´ ë°›ì•„ìš”",
    "emotion": "anxious",
    "timestamp": 1704902400000
  }
}
```

**í•„ë“œ ì„¤ëª…**:
- `message` (string): ì‚¬ìš©ì ë©”ì‹œì§€ (STT ê²°ê³¼)
- `emotion` (string|null): í˜„ì¬ ì–¼êµ´ ê°ì • (8ê°œ ê°ì • ì¤‘ í•˜ë‚˜ ë˜ëŠ” null)
  - `happy`, `sad`, `angry`, `anxious`, `neutral`, `surprised`, `disgusted`, `fearful`
- `timestamp` (number): ìš”ì²­ ì‹œê°„ (ë°€ë¦¬ì´ˆ)

### ë°±ì—”ë“œ â†’ í”„ë¡ íŠ¸ì—”ë“œ (ì‘ë‹µ)

**3ë‹¨ê³„ ìŠ¤íŠ¸ë¦¬ë°**:

**1ë‹¨ê³„: ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘**
```json
{
  "type": "ai_stream_begin",
  "data": {}
}
```

**2ë‹¨ê³„: ì‘ë‹µ ì²­í¬ ì „ì†¡ (ì—¬ëŸ¬ ë²ˆ)**
```json
{
  "type": "ai_stream_chunk",
  "data": {
    "chunk": "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ë°›ê³  ê³„ì‹œëŠ”êµ°ìš”. "
  }
}
```

âš ï¸ **ì¤‘ìš”**: í•„ë“œëª…ì€ ë°˜ë“œì‹œ `chunk`ì—¬ì•¼ í•©ë‹ˆë‹¤ (`text` ì•„ë‹˜!)

**3ë‹¨ê³„: ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ**
```json
{
  "type": "ai_stream_complete",
  "data": {}
}
```

**ì—ëŸ¬ ë°œìƒ ì‹œ**:
```json
{
  "type": "ai_stream_error",
  "data": {
    "error": "AI ì„œë¹„ìŠ¤ê°€ ì¼ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
  }
}
```

---

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### PostgreSQL ë§ˆì´ê·¸ë ˆì´ì…˜ SQL

```sql
-- conversations í…Œì´ë¸” ìƒì„±
CREATE TABLE IF NOT EXISTS conversations (
    id SERIAL PRIMARY KEY,
    session_id VARCHAR(255) NOT NULL,
    user_message TEXT NOT NULL,
    ai_response TEXT NOT NULL,
    emotion VARCHAR(50),
    timestamp BIGINT NOT NULL,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    FOREIGN KEY (session_id) REFERENCES sessions(session_id) ON DELETE CASCADE
);

-- ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)
CREATE INDEX idx_conversations_session ON conversations(session_id);
CREATE INDEX idx_conversations_timestamp ON conversations(timestamp DESC);
CREATE INDEX idx_conversations_created_at ON conversations(created_at DESC);

-- ì„¸ì…˜ë³„ ëŒ€í™” ì¡°íšŒ í•¨ìˆ˜ (ìµœê·¼ 10ê°œ)
CREATE OR REPLACE FUNCTION get_recent_conversations(p_session_id VARCHAR)
RETURNS TABLE (
    user_message TEXT,
    ai_response TEXT,
    emotion VARCHAR(50),
    timestamp BIGINT
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        c.user_message,
        c.ai_response,
        c.emotion,
        c.timestamp
    FROM conversations c
    WHERE c.session_id = p_session_id
    ORDER BY c.timestamp ASC
    LIMIT 10;
END;
$$ LANGUAGE plpgsql;
```

---

## ğŸ”§ êµ¬í˜„ ì½”ë“œ

### 1. í™˜ê²½ ë³€ìˆ˜ (.env)

```bash
# Gemini AI API Key
GEMINI_API_KEY=your-gemini-api-key-here

# Database (Supabase PostgreSQL)
DATABASE_URL=postgresql://user:password@host:port/database

# JWT Secret
JWT_SECRET_KEY=your-secret-key

# Rate Limiting
MAX_AI_REQUESTS_PER_MINUTE=10
```

### 2. ì˜ì¡´ì„± (requirements.txt)

```txt
fastapi>=0.104.0
uvicorn[standard]>=0.24.0
websockets>=12.0
google-generativeai>=0.3.0
python-dotenv>=1.0.0
asyncpg>=0.29.0
pydantic>=2.5.0
```

### 3. AI ì‘ë‹µ ìƒì„± í•¨ìˆ˜ (ai_service.py)

```python
import os
import asyncio
from typing import AsyncGenerator, Optional, List, Dict
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()

# Gemini API ì´ˆê¸°í™”
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ê°ì •ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
EMOTION_PROMPTS = {
    "anxious": "ë‚´ë‹´ìê°€ ë¶ˆì•ˆí•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•ˆì •ê°ì„ ì£¼ëŠ” í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”. ê±±ì •ì„ ê²½ì²­í•˜ê³  êµ¬ì²´ì ì¸ ëŒ€ì²˜ ë°©ë²•ì„ ì œì‹œí•˜ì„¸ìš”.",
    "sad": "ë‚´ë‹´ìê°€ ìš°ìš¸í•´í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê³µê°ê³¼ ìœ„ë¡œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”. ê°ì •ì„ ìˆ˜ìš©í•˜ê³  ê¸ì •ì ì¸ ì¸¡ë©´ì„ ì°¾ë„ë¡ ë„ì™€ì£¼ì„¸ìš”.",
    "angry": "ë‚´ë‹´ìê°€ í™”ê°€ ë‚˜ ìˆìŠµë‹ˆë‹¤. ê°ì •ì„ ìˆ˜ìš©í•˜ê³  ì§„ì •ì‹œí‚¤ëŠ” ë° ì§‘ì¤‘í•˜ì„¸ìš”. ë¶„ë…¸ì˜ ì›ì¸ì„ íƒìƒ‰í•˜ê³  ê±´ì„¤ì ì¸ í‘œí˜„ ë°©ë²•ì„ ì œì•ˆí•˜ì„¸ìš”.",
    "happy": "ë‚´ë‹´ìì˜ ê¸ì •ì ì¸ ìƒíƒœë¥¼ ê°•í™”í•˜ì„¸ìš”. í–‰ë³µí•œ ìˆœê°„ì„ ë” ê¹Šì´ íƒìƒ‰í•˜ê³  ì´ëŸ¬í•œ ìƒíƒœë¥¼ ìœ ì§€í•˜ëŠ” ë°©ë²•ì„ í•¨ê»˜ ìƒê°í•˜ì„¸ìš”.",
    "fearful": "ë‚´ë‹´ìê°€ ë‘ë ¤ì›€ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤. ì•ˆì „ê°ì„ ì œê³µí•˜ê³  ë‘ë ¤ì›€ì˜ ê·¼ì›ì„ í•¨ê»˜ íƒìƒ‰í•˜ì„¸ìš”. ì‘ì€ ë‹¨ê³„ë¶€í„° ì‹œì‘í•˜ëŠ” ëŒ€ì²˜ ë°©ë²•ì„ ì œì•ˆí•˜ì„¸ìš”.",
    "surprised": "ë‚´ë‹´ìê°€ ë†€ëŒì„ ê²½í—˜í–ˆìŠµë‹ˆë‹¤. ê·¸ ê²½í—˜ì— ëŒ€í•´ ìì„¸íˆ ë“¤ì–´ë³´ê³  ì ì ˆí•œ ë°˜ì‘ì„ ë•ìŠµë‹ˆë‹¤.",
    "disgusted": "ë‚´ë‹´ìê°€ ë¶ˆì¾Œê°ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤. ê°ì •ì„ ì¸ì •í•˜ê³  ê²½ê³„ ì„¤ì •ì˜ ì¤‘ìš”ì„±ì„ ë‹¤ë£¨ì„¸ìš”.",
    "neutral": "ì¤‘ë¦½ì ì¸ í†¤ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”. ë‚´ë‹´ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³  í•„ìš”í•œ ì§€ì§€ë¥¼ ì œê³µí•˜ì„¸ìš”."
}

BASE_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ì „ë¬¸ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
ê³µê°ì ì´ê³  ë”°ëœ»í•œ íƒœë„ë¡œ ë‚´ë‹´ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³ , ì¸ì§€í–‰ë™ì¹˜ë£Œ(CBT) ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ë„ì›€ì„ ì œê³µí•˜ì„¸ìš”.

ì‘ë‹µ ê°€ì´ë“œë¼ì¸:
- í•œ ë²ˆì— 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ë‹µí•˜ì„¸ìš”
- ë‚´ë‹´ìì˜ ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ê³  ìˆ˜ìš©í•˜ì„¸ìš”
- êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ì§ˆë¬¸ì´ë‚˜ ì œì•ˆì„ í•˜ì„¸ìš”
- ì „ë¬¸ì ì´ë©´ì„œë„ ë”°ëœ»í•œ í†¤ì„ ìœ ì§€í•˜ì„¸ìš”
- íŒë‹¨í•˜ì§€ ë§ê³  ê²½ì²­í•˜ì„¸ìš”
"""

def build_system_prompt(emotion: Optional[str]) -> str:
    """ê°ì •ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    emotion_guidance = EMOTION_PROMPTS.get(emotion, EMOTION_PROMPTS["neutral"])
    return f"{BASE_SYSTEM_PROMPT}\n\ní˜„ì¬ ê°ì • ìƒíƒœ: {emotion_guidance}"

async def get_conversation_history(session_id: str, db_pool) -> List[Dict[str, str]]:
    """ì„¸ì…˜ì˜ ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ (ìµœê·¼ 10ê°œ)"""
    async with db_pool.acquire() as conn:
        rows = await conn.fetch(
            """
            SELECT user_message, ai_response, emotion
            FROM conversations
            WHERE session_id = $1
            ORDER BY timestamp ASC
            LIMIT 10
            """,
            session_id
        )

        history = []
        for row in rows:
            history.append({
                "role": "user",
                "parts": [row["user_message"]]
            })
            history.append({
                "role": "model",
                "parts": [row["ai_response"]]
            })

        return history

async def generate_ai_response(
    user_message: str,
    emotion: Optional[str],
    session_id: str,
    db_pool
) -> AsyncGenerator[str, None]:
    """
    Gemini AIë¡œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±

    Args:
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        emotion: í˜„ì¬ ê°ì • ìƒíƒœ (8ê°œ ê°ì • ì¤‘ í•˜ë‚˜)
        session_id: ì„¸ì…˜ ID (ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒìš©)
        db_pool: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€

    Yields:
        AI ì‘ë‹µ ì²­í¬ (í…ìŠ¤íŠ¸)
    """
    # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = build_system_prompt(emotion)

    # 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    conversation_history = await get_conversation_history(session_id, db_pool)

    # 3. Gemini ëª¨ë¸ ì´ˆê¸°í™”
    model = genai.GenerativeModel(
        model_name='gemini-1.5-pro',
        system_instruction=system_prompt
    )

    # 4. í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
    conversation_history.append({
        "role": "user",
        "parts": [user_message]
    })

    # 5. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±
    try:
        response = model.generate_content(
            conversation_history,
            stream=True,
            generation_config={
                "temperature": 0.7,
                "top_p": 0.8,
                "top_k": 40,
                "max_output_tokens": 1024,
            }
        )

        # 6. ì²­í¬ ë‹¨ìœ„ë¡œ yield (ìì—°ìŠ¤ëŸ¬ìš´ ì†ë„)
        for chunk in response:
            if chunk.text:
                yield chunk.text
                await asyncio.sleep(0.05)  # 50ms ê°„ê²© (ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸° ì†ë„)

    except Exception as e:
        raise Exception(f"Gemini AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {str(e)}")

async def save_conversation(
    session_id: str,
    user_message: str,
    ai_response: str,
    emotion: Optional[str],
    timestamp: int,
    db_pool
) -> None:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
    async with db_pool.acquire() as conn:
        await conn.execute(
            """
            INSERT INTO conversations (session_id, user_message, ai_response, emotion, timestamp)
            VALUES ($1, $2, $3, $4, $5)
            """,
            session_id,
            user_message,
            ai_response,
            emotion,
            timestamp
        )
```

### 4. WebSocket í•¸ë“¤ëŸ¬ (websocket_handlers.py)

```python
import asyncio
import logging
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict, Any
from datetime import datetime, timedelta
from collections import defaultdict

from .ai_service import generate_ai_response, save_conversation

logger = logging.getLogger(__name__)

# Rate limiting (ì‚¬ìš©ìë‹¹ ë¶„ë‹¹ ìš”ì²­ ì œí•œ)
rate_limit_tracker: Dict[str, list] = defaultdict(list)
MAX_REQUESTS_PER_MINUTE = 10

def check_rate_limit(session_id: str) -> bool:
    """Rate limiting ì²´í¬ (ë¶„ë‹¹ 10íšŒ ì œí•œ)"""
    now = datetime.now()
    one_minute_ago = now - timedelta(minutes=1)

    # 1ë¶„ ì´ë‚´ ìš”ì²­ë§Œ í•„í„°ë§
    rate_limit_tracker[session_id] = [
        req_time for req_time in rate_limit_tracker[session_id]
        if req_time > one_minute_ago
    ]

    # ì œí•œ ì´ˆê³¼ í™•ì¸
    if len(rate_limit_tracker[session_id]) >= MAX_REQUESTS_PER_MINUTE:
        return False

    # í˜„ì¬ ìš”ì²­ ì¶”ê°€
    rate_limit_tracker[session_id].append(now)
    return True

async def handle_ai_response_request(
    websocket: WebSocket,
    message: Dict[str, Any],
    session_id: str,
    db_pool
) -> None:
    """
    AI ì‘ë‹µ ìš”ì²­ ì²˜ë¦¬ ë° ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì „ì†¡

    Args:
        websocket: WebSocket ì—°ê²°
        message: í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë°›ì€ ë©”ì‹œì§€
        session_id: ì„¸ì…˜ ID
        db_pool: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€
    """
    try:
        # 1. ë°ì´í„° ì¶”ì¶œ
        data = message.get("data", {})
        user_message = data.get("message", "").strip()
        emotion = data.get("emotion")
        timestamp = data.get("timestamp", int(datetime.now().timestamp() * 1000))

        # 2. ì…ë ¥ ê²€ì¦
        if not user_message:
            await websocket.send_json({
                "type": "ai_stream_error",
                "data": {"error": "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}
            })
            return

        if len(user_message) > 2000:
            await websocket.send_json({
                "type": "ai_stream_error",
                "data": {"error": "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 2000ì)"}
            })
            return

        # 3. Rate limiting ì²´í¬
        if not check_rate_limit(session_id):
            await websocket.send_json({
                "type": "ai_stream_error",
                "data": {"error": "ìš”ì²­ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”"}
            })
            logger.warning(f"[Rate Limit] session={session_id}, message={user_message[:50]}...")
            return

        logger.info(f"[AI Request] session={session_id}, emotion={emotion}, message={user_message[:100]}...")

        # 4. ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì•Œë¦¼
        await websocket.send_json({
            "type": "ai_stream_begin",
            "data": {}
        })

        # 5. AI ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
        full_response = ""
        async for chunk in generate_ai_response(user_message, emotion, session_id, db_pool):
            # ì²­í¬ ì „ì†¡
            await websocket.send_json({
                "type": "ai_stream_chunk",
                "data": {"chunk": chunk}  # âš ï¸ í•„ë“œëª… "chunk" í•„ìˆ˜!
            })
            full_response += chunk

        # 6. ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ ì•Œë¦¼
        await websocket.send_json({
            "type": "ai_stream_complete",
            "data": {}
        })

        logger.info(f"[AI Response] session={session_id}, length={len(full_response)}, response={full_response[:100]}...")

        # 7. ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
        await save_conversation(
            session_id=session_id,
            user_message=user_message,
            ai_response=full_response,
            emotion=emotion,
            timestamp=timestamp,
            db_pool=db_pool
        )

    except Exception as e:
        logger.error(f"[AI Error] session={session_id}, error={str(e)}", exc_info=True)

        # ì—ëŸ¬ ì „ì†¡
        await websocket.send_json({
            "type": "ai_stream_error",
            "data": {"error": f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}
        })

async def websocket_session_endpoint(websocket: WebSocket, session_id: str, db_pool):
    """
    ì„¸ì…˜ WebSocket ì—”ë“œí¬ì¸íŠ¸

    ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ì— ì´ í•¸ë“¤ëŸ¬ë¥¼ ì¶”ê°€í•˜ì„¸ìš”
    """
    await websocket.accept()

    try:
        while True:
            # ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive_json()

            # AI ì‘ë‹µ ìš”ì²­ ì²˜ë¦¬ (ìƒˆë¡œ ì¶”ê°€ëœ ë¶€ë¶„)
            if message.get("type") == "request_ai_response":
                await handle_ai_response_request(websocket, message, session_id, db_pool)

            # ê¸°ì¡´ ë©”ì‹œì§€ íƒ€ì… ì²˜ë¦¬
            elif message.get("type") == "emotion_update":
                # ... ê¸°ì¡´ ì½”ë“œ ìœ ì§€
                pass

            elif message.get("type") == "vad_metrics":
                # ... ê¸°ì¡´ ì½”ë“œ ìœ ì§€
                pass

            # ... ê¸°íƒ€ ë©”ì‹œì§€ íƒ€ì…

    except WebSocketDisconnect:
        logger.info(f"[WebSocket] Session {session_id} disconnected")
    except Exception as e:
        logger.error(f"[WebSocket Error] session={session_id}, error={str(e)}", exc_info=True)
```

### 5. ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ í†µí•© (main.py)

```python
from fastapi import FastAPI, WebSocket, WebSocketDisconnect
import asyncpg
import os
from dotenv import load_dotenv

from .websocket_handlers import websocket_session_endpoint

load_dotenv()

app = FastAPI(title="BeMore Backend API")

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€
db_pool = None

@app.on_event("startup")
async def startup():
    global db_pool
    db_pool = await asyncpg.create_pool(
        os.getenv("DATABASE_URL"),
        min_size=5,
        max_size=20
    )
    print("âœ… Database connection pool created")

@app.on_event("shutdown")
async def shutdown():
    await db_pool.close()
    print("âœ… Database connection pool closed")

@app.websocket("/ws/session/{session_id}")
async def session_websocket(websocket: WebSocket, session_id: str):
    """ì„¸ì…˜ WebSocket ì—”ë“œí¬ì¸íŠ¸"""
    await websocket_session_endpoint(websocket, session_id, db_pool)
```

---

## âœ… í…ŒìŠ¤íŠ¸ ì ˆì°¨

### 1. ë¡œì»¬ í™˜ê²½ ì„¤ì •

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# GEMINI_API_KEY ì„¤ì •

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# 3. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜
psql $DATABASE_URL < migrations/create_conversations_table.sql

# 4. ì„œë²„ ì‹¤í–‰
uvicorn main:app --reload --port 8000
```

### 2. WebSocket í…ŒìŠ¤íŠ¸ (Python)

```python
import asyncio
import websockets
import json

async def test_ai_chat():
    uri = "ws://localhost:8000/ws/session/test_session_123"

    async with websockets.connect(uri) as websocket:
        # AI ì‘ë‹µ ìš”ì²­
        await websocket.send(json.dumps({
            "type": "request_ai_response",
            "data": {
                "message": "ì•ˆë…•í•˜ì„¸ìš”, ìš”ì¦˜ ìš°ìš¸í•´ìš”",
                "emotion": "sad",
                "timestamp": 1704902400000
            }
        }))

        print("âœ… Request sent")

        # ì‘ë‹µ ìˆ˜ì‹ 
        full_response = ""
        while True:
            response = await websocket.recv()
            message = json.loads(response)

            if message["type"] == "ai_stream_begin":
                print("ğŸŸ¢ Stream started")

            elif message["type"] == "ai_stream_chunk":
                chunk = message["data"]["chunk"]
                full_response += chunk
                print(f"ğŸ“ Chunk: {chunk}")

            elif message["type"] == "ai_stream_complete":
                print(f"âœ… Stream complete\n\nFull response:\n{full_response}")
                break

            elif message["type"] == "ai_stream_error":
                print(f"âŒ Error: {message['data']['error']}")
                break

asyncio.run(test_ai_chat())
```

### 3. í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸

1. ë°±ì—”ë“œ ì„œë²„ ì‹¤í–‰: `uvicorn main:app --reload`
2. í”„ë¡ íŠ¸ì—”ë“œ ì„œë²„ ì‹¤í–‰: `npm run dev`
3. ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†: `http://localhost:5173`
4. ì„¸ì…˜ ì‹œì‘ ë²„íŠ¼ í´ë¦­
5. ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
6. ìŒì„±ìœ¼ë¡œ ë§í•˜ê¸°: "ì•ˆë…•í•˜ì„¸ìš”"
7. í™•ì¸ ì‚¬í•­:
   - âœ… ì‚¬ìš©ì ë©”ì‹œì§€ê°€ í™”ë©´ì— í‘œì‹œ
   - âœ… AI ì‘ë‹µì´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°
   - âœ… TTSë¡œ AI ìŒì„± ì¬ìƒ
   - âœ… ê°œë°œì ë„êµ¬ì—ì„œ WebSocket ë©”ì‹œì§€ í™•ì¸

### 4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
# ì‘ë‹µ ì‹œê°„ ì¸¡ì • (ì²« ë²ˆì§¸ ì²­í¬ <2ì´ˆ)
time python test_ai_chat.py

# ë™ì‹œ ì—°ê²° í…ŒìŠ¤íŠ¸ (10 concurrent users)
python test_concurrent_sessions.py
```

---

## ğŸš€ ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Render.com ë°°í¬

```bash
# 1. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Render Dashboard)
GEMINI_API_KEY=your-api-key
DATABASE_URL=postgresql://...
JWT_SECRET_KEY=...

# 2. Build Command
pip install -r requirements.txt

# 3. Start Command
uvicorn main:app --host 0.0.0.0 --port $PORT

# 4. Health Check
GET /health
```

### ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] âœ… GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
- [ ] âœ… DATABASE_URL ì„¤ì • (PostgreSQL)
- [ ] âœ… conversations í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ
- [ ] âœ… Rate limiting ì„¤ì • í™•ì¸
- [ ] âœ… ë¡œê¹… ì„¤ì • (ì—ëŸ¬ ì¶”ì )
- [ ] âœ… CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ ë„ë©”ì¸ í—ˆìš©)
- [ ] âœ… ë¡œì»¬ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] âœ… í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼

---

## ğŸ“Š ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

- **ì²« ì²­í¬ ì‘ë‹µ ì‹œê°„**: < 2ì´ˆ
- **ìŠ¤íŠ¸ë¦¬ë° ì†ë„**: 50-100ms/ì²­í¬
- **ì „ì²´ ì‘ë‹µ ì‹œê°„**: < 10ì´ˆ (ì¼ë°˜ì ì¸ ë‹µë³€)
- **ë™ì‹œ ì—°ê²°**: ì„¸ì…˜ë‹¹ 1ê°œ WebSocket
- **ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬**: < 100ms

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. í•„ìˆ˜ í•„ë“œëª…
```python
# âœ… ì˜¬ë°”ë¥¸ í•„ë“œëª…
{"type": "ai_stream_chunk", "data": {"chunk": "í…ìŠ¤íŠ¸"}}

# âŒ ì˜ëª»ëœ í•„ë“œëª… (í”„ë¡ íŠ¸ì—”ë“œ íŒŒì‹± ì‹¤íŒ¨)
{"type": "ai_stream_chunk", "data": {"text": "í…ìŠ¤íŠ¸"}}
```

### 2. ê°ì • ì§€ì›
8ê°œ ê°ì •ì„ ëª¨ë‘ ì§€ì›í•´ì•¼ í•©ë‹ˆë‹¤:
- `happy`, `sad`, `angry`, `anxious`, `neutral`, `surprised`, `disgusted`, `fearful`

### 3. í•œêµ­ì–´ ì¸ì½”ë”©
- UTF-8 ì¸ì½”ë”© í•„ìˆ˜
- ëª¨ë“  AI ì‘ë‹µì€ í•œêµ­ì–´ë¡œ

### 4. ë³´ì•ˆ
```python
# ë¯¼ê° ì •ë³´ ë¡œê¹… ë°©ì§€
logger.info(f"User message: {user_message[:50]}...")  # âœ… ì¼ë¶€ë§Œ
logger.info(f"User message: {user_message}")  # âŒ ì „ì²´ ë¡œê¹… ê¸ˆì§€
```

---

## ğŸ” íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Q1: Gemini API ì—ëŸ¬ (403 Forbidden)
**ì›ì¸**: API í‚¤ê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ í• ë‹¹ëŸ‰ ì´ˆê³¼
**í•´ê²°**:
1. API í‚¤ í™•ì¸: https://makersuite.google.com/app/apikey
2. í• ë‹¹ëŸ‰ í™•ì¸: https://console.cloud.google.com/

### Q2: ìŠ¤íŠ¸ë¦¬ë°ì´ ë©ˆì¶¤
**ì›ì¸**: WebSocket ì—°ê²° íƒ€ì„ì•„ì›ƒ
**í•´ê²°**:
```python
# uvicorn --timeout-keep-alive 300 ì¶”ê°€
uvicorn main:app --timeout-keep-alive 300
```

### Q3: ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì €ì¥ ì•ˆ ë¨
**ì›ì¸**: ì™¸ë˜ í‚¤ ì œì•½ ì¡°ê±´
**í•´ê²°**:
```sql
-- sessions í…Œì´ë¸”ì— session_idê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
SELECT * FROM sessions WHERE session_id = 'test_session_123';
```

### Q4: Rate limiting ì‘ë™ ì•ˆ í•¨
**ì›ì¸**: ì„œë²„ ì¬ì‹œì‘ ì‹œ ë©”ëª¨ë¦¬ ì´ˆê¸°í™”
**í•´ê²°**: Redis ì‚¬ìš© (ì„ íƒ)
```python
import redis
r = redis.Redis(host='localhost', port=6379, db=0)
```

---

## ğŸ“ êµ¬í˜„ í›„ í™•ì¸

êµ¬í˜„ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

1. âœ… ë¡œì»¬ í…ŒìŠ¤íŠ¸ í†µê³¼
2. âœ… í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼
3. âœ… ì²« ì²­í¬ ì‘ë‹µ ì‹œê°„ < 2ì´ˆ
4. âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥ í™•ì¸
5. âœ… Rate limiting ë™ì‘ í™•ì¸
6. âœ… ì—ëŸ¬ í•¸ë“¤ë§ í™•ì¸

**í”„ë¡ íŠ¸ì—”ë“œ íŒ€ì— ì•Œë ¤ì£¼ì„¸ìš”**:
- ë°±ì—”ë“œ ë°°í¬ URL
- í…ŒìŠ¤íŠ¸ ê³„ì • ì •ë³´ (ìˆë‹¤ë©´)
- API í‚¤ ì„¤ì • ìƒíƒœ

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- [Gemini API - Streaming](https://ai.google.dev/gemini-api/docs/text-generation?lang=python#generate-a-text-stream)
- [FastAPI WebSocket](https://fastapi.tiangolo.com/advanced/websockets/)
- [asyncpg Documentation](https://magicstack.github.io/asyncpg/current/)
- [Frontend Integration Spec](./BACKEND_AI_VOICE_REQUEST.md)

---

**êµ¬í˜„ ì˜ˆìƒ ì‹œê°„**: 30ë¶„ ~ 1ì‹œê°„
**ë‚œì´ë„**: ì¤‘ê°„
**ìš°ì„ ìˆœìœ„**: ğŸ”´ High (í•µì‹¬ ê¸°ëŠ¥)

ì´ í”„ë¡¬í”„íŠ¸ë¥¼ Claude Codeì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸°í•˜ë©´ ì¦‰ì‹œ êµ¬í˜„ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
```

---

## ğŸ¯ ì‚¬ìš© ë°©ë²•

1. **ìœ„ ì „ì²´ ë‚´ìš©ì„ ë³µì‚¬**
2. **Claude Code ì—´ê¸°**
3. **ë¶™ì—¬ë„£ê¸°**
4. **Enter**

Claude Codeê°€ ìë™ìœ¼ë¡œ:
- í•„ìš”í•œ íŒŒì¼ ìƒì„±
- ì½”ë“œ êµ¬í˜„
- ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ SQL ìƒì„±
- í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„±

ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

---

## ğŸ“ ë°±ì—”ë“œ íŒ€ ì „ë‹¬ ë©”ì‹œì§€

```
ì•ˆë…•í•˜ì„¸ìš” ë°±ì—”ë“œ íŒ€!

í”„ë¡ íŠ¸ì—”ë“œ AI ìŒì„± ìƒë‹´ ê¸°ëŠ¥ì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.
ë°±ì—”ë“œ AI ì‘ë‹µ ìƒì„± ê¸°ëŠ¥ë§Œ êµ¬í˜„í•˜ì‹œë©´ ì¦‰ì‹œ ì‘ë™í•©ë‹ˆë‹¤.

ğŸ“„ êµ¬í˜„ ê°€ì´ë“œ: docs/integration/backend/BACKEND_AI_IMPLEMENTATION_PROMPT.md

ì´ íŒŒì¼ì„ Claude Codeì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸°ë§Œ í•˜ì‹œë©´
30ë¶„ ì•ˆì— ëª¨ë“  ì½”ë“œê°€ ìë™ ìƒì„±ë©ë‹ˆë‹¤.

êµ¬í˜„ í›„ í”„ë¡ íŠ¸ì—”ë“œ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤!

ê°ì‚¬í•©ë‹ˆë‹¤ ğŸ˜Š
```
